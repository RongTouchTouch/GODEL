{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/PrithivirajDamodaran/Parrot_Paraphraser.git"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the paraot model to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from parrot import Parrot\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "''' \n",
    "uncomment to get reproducable paraphrase generations\n",
    "def random_state(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "random_state(1234)\n",
    "'''\n",
    "\n",
    "#Init models (make sure you init ONLY once if you integrate this to your code)\n",
    "parrot = Parrot(model_tag=\"prithivida/parrot_paraphraser_on_T5\", use_gpu=False)\n",
    "\n",
    "phrases = [\"Can you recommed some upscale restaurants in Newyork?\",\n",
    "           \"What are the famous places we should not miss in Russia?\"\n",
    "]\n",
    "\n",
    "for phrase in phrases:\n",
    "  print(\"-\"*100)\n",
    "  print(\"Input_phrase: \", phrase)\n",
    "  print(\"-\"*100)\n",
    "  para_phrases = parrot.augment(input_phrase=phrase)\n",
    "  for para_phrase in para_phrases:\n",
    "   print(para_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss\n",
    "with open('origin.txt','r') as f:\n",
    "    ss = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "para = []\n",
    "for s in ss:\n",
    "    s = s.replace('\\n','')\n",
    "    temp = parrot.augment(input_phrase= s)\n",
    "    if temp == None:\n",
    "        continue\n",
    "    for x in temp:\n",
    "        para.append(x[0] + \"|||\" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('para.txt', 'w') as f: # para -> origin\n",
    "    for line in para:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use the pegasus model to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n",
    "model_name = 'tuner007/pegasus_paraphrase'\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n",
    "\n",
    "def get_response(input_text,num_return_sequences,num_beams):\n",
    "  batch = tokenizer([input_text],truncation=True,padding='longest',max_length=60, return_tensors=\"pt\").to(torch_device)\n",
    "  translated = model.generate(**batch,max_length=60,num_beams=num_beams, num_return_sequences=num_return_sequences, temperature=1.5)\n",
    "  tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n",
    "  return tgt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_beams = 5\n",
    "num_return_sequences = 5\n",
    "pega = []\n",
    "for s in ss:\n",
    "    s = s.replace('\\n','')\n",
    "    temp = get_response(s,num_return_sequences,num_beams)\n",
    "    if temp == None:\n",
    "        continue\n",
    "    if len(temp) == 0:\n",
    "        continue\n",
    "    for x in temp:\n",
    "        para.append(x + \"|||\" + s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pega.txt', 'w') as f: # para -> origin\n",
    "    for line in pega:\n",
    "        f.write(f\"{line}\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### when it comes to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = []\n",
    "# origin = []\n",
    "# with open('para.txt','r') as f: # also pega.txt\n",
    "#     ss = f.readlines()\n",
    "#     temp = ss.split('|||')\n",
    "#     raw.append(temp[0])\n",
    "#     origin.append(temp[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4 (main, Apr  2 2022, 09:04:19) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
